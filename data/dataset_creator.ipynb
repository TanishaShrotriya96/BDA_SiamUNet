{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all' # default is ‘last_expr’\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "from random import shuffle\n",
    "import math\n",
    "from shapely import wkt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5598/5598 [00:00<00:00, 1866431.94it/s]\n",
      "100%|██████████| 1866/1866 [00:00<00:00, 1870148.45it/s]\n",
      "100%|██████████| 1866/1866 [00:00<00:00, 1875076.97it/s]\n",
      "100%|██████████| 12738/12738 [00:00<00:00, 1819288.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.51 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xbd_root = '../../data/'\n",
    "#all_disasters =['guatemala-volcano', 'hurricane-florence', 'hurricane-harvey', 'hurricane-matthew', 'hurricane-michael', 'mexico-earthquake', 'midwest-flooding', 'palu-tsunami', 'santa-rosa-wildfire', 'socal-fire', 'joplin-tornado', 'lower-puna-volcano', 'moore-tornado', 'nepal-flooding', 'pinery-bushfire', 'portugal-wildfire', 'sunda-tsunami', 'tuscaloosa-tornado', 'woolsey-fire']\n",
    "all_disasters = ['hurricane-harvey']\n",
    "label_dirs = [\n",
    "    xbd_root + 'raw/train/labels',\n",
    "    xbd_root + 'raw/test/labels',\n",
    "    xbd_root + 'raw/hold/labels',\n",
    "    xbd_root + 'raw/tier3/labels'\n",
    "]\n",
    "all_files = defaultdict(list)  # wind disaster to list of files (no extension)\n",
    "\n",
    "all_disasters_tup = tuple(all_disasters)\n",
    "\n",
    "for label_dir in label_dirs:\n",
    "    for p in tqdm(os.listdir(label_dir)):\n",
    "        \n",
    "        if not p.startswith(all_disasters_tup):\n",
    "            continue\n",
    "        \n",
    "        if not p.endswith('_post_disaster.json'):\n",
    "            continue\n",
    "        \n",
    "        full_path = label_dir+'/'+p\n",
    "        rel_path = full_path.split(xbd_root)[1]\n",
    "        \n",
    "        # example: hurricane-matthew_00000000_post_disaster.json\n",
    "        disaster_name = p.split('_')[0]\n",
    "        file = rel_path.split('_post_disaster.json')[0]\n",
    "        \n",
    "        all_files[disaster_name].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hurricane-harvey, 522\n"
     ]
    }
   ],
   "source": [
    "for disaster_name, files in all_files.items():\n",
    "    print(f'{disaster_name}, {len(files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hurricane-harvey, train 418, val 53\n"
     ]
    }
   ],
   "source": [
    "other_splits = defaultdict(dict)  # disasters other than the wind disasters to train/val/test\n",
    "\n",
    "for disaster_name, files in all_files.items():\n",
    "\n",
    "    \n",
    "    shuffle(files)\n",
    "    \n",
    "    num_train_tiles = math.ceil(0.8 * len(files))\n",
    "    num_val_tiles = math.ceil(0.1 * len(files))\n",
    "    \n",
    "    other_splits[disaster_name]['train'] = sorted(files[:num_train_tiles])\n",
    "    other_splits[disaster_name]['val'] = sorted(files[num_train_tiles:num_train_tiles + num_val_tiles])\n",
    "    other_splits[disaster_name]['test'] = sorted(files[num_train_tiles + num_val_tiles:])\n",
    "\n",
    "    print(f\"{disaster_name}, train {len(other_splits[disaster_name]['train'])}, val {len(other_splits[disaster_name]['val'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../constants/splits/final_mdl_all_disaster_splits.json', 'w') as f:\n",
    "    json.dump(other_splits, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1b6b5bc508404414507f1b79b6a3b7cfbb843d2d72dd2893c13b634dc5b16f97"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('spatial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
